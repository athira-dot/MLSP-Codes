{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Question_05.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat May 15 21:33:10 2021\n",
    "\n",
    "@author: athira\n",
    "\"\"\"\n",
    "#%%\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from libsvm.svm import *\n",
    "from libsvm.svmutil import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "f1 = open(\"movie_reviews/movieReviews1000.txt\", \"r\")\n",
    "data=f1.readlines()  #collection of all sentances\n",
    "n=len(data)\n",
    "\n",
    "#print(data[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the labels of  data and collecting labels\n",
    "data_sent=[]\n",
    "labels=[]\n",
    "for i in range(n):\n",
    "    #print(len(data[i][-2]))\n",
    "    if(data[i][-2]=='0'):\n",
    "        labels.append(0)\n",
    "    if(data[i][-2]=='1'):\n",
    "        labels.append(1)\n",
    "\n",
    "    data_sent.append((data[i])[:-5])\n",
    "\n",
    "labels=np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3487"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "#collecting words in sentances of data\n",
    "data_w=[]\n",
    "for i in data_sent:\n",
    "  b=i.split()\n",
    "  data_w.append(b)\n",
    "  #print(b)\n",
    "\n",
    "data_w[0]\n",
    "data_word=[]   #lists of words in document \n",
    "for i in data_w:\n",
    "  for word in i:\n",
    "    data_word.append(word)\n",
    "\n",
    "len(data_word)\n",
    "\n",
    "unique=set(data_word)  #unique set of words\n",
    "len(unique)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_n(data_w_n,unique):\n",
    "    dict_=dict.fromkeys(unique,0)\n",
    "    for word in data_w_n:\n",
    "      dict_[word]= dict_[word]+1\n",
    "    return(dict_)\n",
    "\n",
    "#print(dict_n(data_w[0],unique))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find term frequency\n",
    "def tf(dict_n,word_n):\n",
    "  #print(dict_n)\n",
    "  tf_dict={}  #term frequency of document \n",
    "  word_count=len(word_n)\n",
    "  for word,count in dict_n.items():\n",
    "    tf_dict[word]=count/float(word_count)\n",
    "  return(tf_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def IDF(doc_list):\n",
    "    idf_dict = {}\n",
    "    N = len(doc_list)\n",
    "    \n",
    "    idf_dict = dict.fromkeys(doc_list[0].keys(), 0)\n",
    "    for doc in doc_list:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idf_dict[word] += 1\n",
    "    \n",
    "    for word, val in idf_dict.items():\n",
    "        idf_dict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=[]\n",
    "for i in range(n):\n",
    "    dic_n=(dict_n(data_w[i],unique)) #dictionary for i th document\n",
    "    doc.append(dic_n)\n",
    "idfs=IDF(doc)\n",
    "\n",
    "#idfs\n",
    "def TFIDF(tffWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tffWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3487"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=[]\n",
    "for i in range(n):\n",
    "    dic_n=(dict_n(data_w[i],unique)) #dictionary for i th document\n",
    "    #to find term frequency of i th document\n",
    "    tf_n=tf(dic_n,data_w[i])\n",
    "    #to find tfidf of i th document\n",
    "    tfidf_n=TFIDF(tf_n,idfs)\n",
    "    count_n=[]\n",
    "    for word,count in tfidf_n.items():\n",
    "        count_n.append(count)\n",
    "    count_n=np.array(count_n)\n",
    "    feature.append(count_n)\n",
    "feature=np.array(feature)\n",
    "\n",
    "np.shape(feature)\n",
    "len(count_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying high dimensional pca\n",
    "#applying high dimensional PCA on X\n",
    "K=10\n",
    "pca = PCA(n_components=K)\n",
    "\n",
    "pca_data=pca.fit_transform(feature)\n",
    "\n",
    "np.shape(pca_data)\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating training and test data\n",
    "train=pca_data[0:750,:] #training data\n",
    "train_label=labels[0:750] #train labels\n",
    "\n",
    "test=pca_data[750:,:]    #test dada\n",
    "test_label=labels[750:]  #test labels\n",
    "\n",
    "\n",
    "train_label=np.array(train_label)\n",
    "test_label=np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat=[]\n",
    "def svm_(train_label,train,ker,test,test_label):\n",
    "    p=svm_problem(train_label,train)\n",
    "\n",
    "    param = svm_parameter()\n",
    "\n",
    "#RBF kernel\n",
    "    c=0.000001\n",
    "    while(c<=100000): \n",
    "\n",
    "        e=0.1\n",
    "        while(e<=1):\n",
    "\n",
    "            param.kernel_type=ker\n",
    "            param.C=c\n",
    "            param.eps=e\n",
    "\n",
    "  ## training  the model\n",
    "            model_=svm_train(p,param)\n",
    "\n",
    "\n",
    "        \n",
    "            #print(\"for training data\")\n",
    "            PREDICT_TEST=svm_predict(train_label,train,model_)\n",
    "\n",
    "            #print(\"for testing data\")\n",
    "            PREDICT_TRAIN=svm_predict(test_label,test,model_)\n",
    "            \n",
    "            #print([K,c,e,ker,PREDICT_TEST[1][0],PREDICT_TRAIN[1][0]])\n",
    "            stat.append([K,c,e,ker,PREDICT_TEST[1][0],PREDICT_TRAIN[1][0],model_.get_nr_sv()])\n",
    "            e=e+0.5\n",
    "        c=c*10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 59.8667% (449/750) (classification)\n",
      "Accuracy = 61.2% (153/250) (classification)\n",
      "Accuracy = 58.8% (441/750) (classification)\n",
      "Accuracy = 65.2% (163/250) (classification)\n",
      "Accuracy = 59.2% (444/750) (classification)\n",
      "Accuracy = 64.8% (162/250) (classification)\n",
      "Accuracy = 57.3333% (430/750) (classification)\n",
      "Accuracy = 67.6% (169/250) (classification)\n",
      "Accuracy = 59.6% (447/750) (classification)\n",
      "Accuracy = 61.2% (153/250) (classification)\n",
      "Accuracy = 59.0667% (443/750) (classification)\n",
      "Accuracy = 64% (160/250) (classification)\n",
      "Accuracy = 59.2% (444/750) (classification)\n",
      "Accuracy = 58.8% (147/250) (classification)\n",
      "Accuracy = 60.9333% (457/750) (classification)\n",
      "Accuracy = 50.8% (127/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54.1333% (406/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54.1333% (406/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54.1333% (406/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54.1333% (406/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54.1333% (406/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54.1333% (406/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.8667% (404/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54.5333% (409/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54.5333% (409/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 58.9333% (442/750) (classification)\n",
      "Accuracy = 64.8% (162/250) (classification)\n",
      "Accuracy = 58.1333% (436/750) (classification)\n",
      "Accuracy = 67.6% (169/250) (classification)\n",
      "Accuracy = 58.2667% (437/750) (classification)\n",
      "Accuracy = 66% (165/250) (classification)\n",
      "Accuracy = 57.3333% (430/750) (classification)\n",
      "Accuracy = 65.6% (164/250) (classification)\n",
      "Accuracy = 57.8667% (434/750) (classification)\n",
      "Accuracy = 66% (165/250) (classification)\n",
      "Accuracy = 57.0667% (428/750) (classification)\n",
      "Accuracy = 67.2% (168/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 53.7333% (403/750) (classification)\n",
      "Accuracy = 38.8% (97/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.2% (98/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 54% (405/750) (classification)\n",
      "Accuracy = 39.6% (99/250) (classification)\n",
      "Accuracy = 58.2667% (437/750) (classification)\n",
      "Accuracy = 62.8% (157/250) (classification)\n",
      "Accuracy = 56.8% (426/750) (classification)\n",
      "Accuracy = 68% (170/250) (classification)\n",
      "Accuracy = 57.2% (429/750) (classification)\n",
      "Accuracy = 60.4% (151/250) (classification)\n",
      "Accuracy = 57.0667% (428/750) (classification)\n",
      "Accuracy = 66.8% (167/250) (classification)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 57.3333% (430/750) (classification)\n",
      "Accuracy = 50.4% (126/250) (classification)\n",
      "Accuracy = 56.5333% (424/750) (classification)\n",
      "Accuracy = 52.4% (131/250) (classification)\n"
     ]
    }
   ],
   "source": [
    "svm_(train_label,train,LINEAR,test,test_label)\n",
    "svm_(train_label,train,POLY,test,test_label)\n",
    "svm_(train_label,train,RBF,test,test_label)\n",
    "svm_(train_label,train,SIGMOID,test,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "[10, 1e-06, 0.1, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1e-06, 0.6, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.1, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.6, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.1, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.6, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.1, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.6, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.1, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.6, 0, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.1, 0, 53.733333333333334, 38.800000000000004, 697]\n",
      "[10, 0.1, 0.6, 0, 53.733333333333334, 38.800000000000004, 696]\n",
      "[10, 1.0, 0.1, 0, 54.0, 39.2, 696]\n",
      "[10, 1.0, 0.6, 0, 54.0, 39.2, 697]\n",
      "[10, 10.0, 0.1, 0, 54.0, 39.6, 694]\n",
      "[10, 10.0, 0.6, 0, 54.0, 39.6, 694]\n",
      "[10, 100.0, 0.1, 0, 59.86666666666667, 61.199999999999996, 687]\n",
      "[10, 100.0, 0.6, 0, 58.8, 65.2, 687]\n",
      "[10, 1000.0, 0.1, 0, 59.199999999999996, 64.8, 666]\n",
      "[10, 1000.0, 0.6, 0, 57.333333333333336, 67.60000000000001, 667]\n",
      "[10, 10000.0, 0.1, 0, 59.599999999999994, 61.199999999999996, 663]\n",
      "[10, 10000.0, 0.6, 0, 59.06666666666667, 64.0, 662]\n",
      "[10, 100000.0, 0.1, 0, 59.199999999999996, 58.8, 662]\n",
      "[10, 100000.0, 0.6, 0, 60.93333333333333, 50.8, 665]\n",
      "[10, 1e-06, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1e-06, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1.0, 0.1, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1.0, 0.6, 1, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 10.0, 0.1, 1, 54.0, 39.2, 698]\n",
      "[10, 10.0, 0.6, 1, 54.0, 39.2, 693]\n",
      "[10, 100.0, 0.1, 1, 54.0, 39.2, 699]\n",
      "[10, 100.0, 0.6, 1, 54.0, 39.2, 698]\n",
      "[10, 1000.0, 0.1, 1, 54.13333333333333, 39.2, 700]\n",
      "[10, 1000.0, 0.6, 1, 54.13333333333333, 39.2, 698]\n",
      "[10, 10000.0, 0.1, 1, 54.13333333333333, 39.2, 703]\n",
      "[10, 10000.0, 0.6, 1, 54.13333333333333, 39.2, 701]\n",
      "[10, 100000.0, 0.1, 1, 54.13333333333333, 39.6, 699]\n",
      "[10, 100000.0, 0.6, 1, 54.13333333333333, 39.6, 699]\n",
      "[10, 1e-06, 0.1, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1e-06, 0.6, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.1, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.6, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.1, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.6, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.1, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.6, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.1, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.6, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.1, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.6, 2, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1.0, 0.1, 2, 53.86666666666666, 38.800000000000004, 698]\n",
      "[10, 1.0, 0.6, 2, 54.0, 39.2, 695]\n",
      "[10, 10.0, 0.1, 2, 54.0, 39.6, 697]\n",
      "[10, 10.0, 0.6, 2, 54.0, 39.6, 697]\n",
      "[10, 100.0, 0.1, 2, 54.53333333333333, 39.6, 692]\n",
      "[10, 100.0, 0.6, 2, 54.53333333333333, 39.6, 694]\n",
      "[10, 1000.0, 0.1, 2, 58.93333333333334, 64.8, 676]\n",
      "[10, 1000.0, 0.6, 2, 58.13333333333334, 67.60000000000001, 677]\n",
      "[10, 10000.0, 0.1, 2, 58.266666666666666, 66.0, 655]\n",
      "[10, 10000.0, 0.6, 2, 57.333333333333336, 65.60000000000001, 655]\n",
      "[10, 100000.0, 0.1, 2, 57.86666666666667, 66.0, 656]\n",
      "[10, 100000.0, 0.6, 2, 57.06666666666666, 67.2, 655]\n",
      "[10, 1e-06, 0.1, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1e-06, 0.6, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.1, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-06, 0.6, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.1, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 9.999999999999999e-05, 0.6, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.1, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.001, 0.6, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.1, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.01, 0.6, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.1, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 0.1, 0.6, 3, 53.733333333333334, 38.800000000000004, 694]\n",
      "[10, 1.0, 0.1, 3, 53.733333333333334, 38.800000000000004, 697]\n",
      "[10, 1.0, 0.6, 3, 53.733333333333334, 38.800000000000004, 696]\n",
      "[10, 10.0, 0.1, 3, 54.0, 39.2, 695]\n",
      "[10, 10.0, 0.6, 3, 54.0, 39.6, 694]\n",
      "[10, 100.0, 0.1, 3, 54.0, 39.6, 696]\n",
      "[10, 100.0, 0.6, 3, 54.0, 39.6, 695]\n",
      "[10, 1000.0, 0.1, 3, 58.266666666666666, 62.8, 688]\n",
      "[10, 1000.0, 0.6, 3, 56.8, 68.0, 687]\n",
      "[10, 10000.0, 0.1, 3, 57.199999999999996, 60.4, 663]\n",
      "[10, 10000.0, 0.6, 3, 57.06666666666666, 66.8, 662]\n",
      "[10, 100000.0, 0.1, 3, 57.333333333333336, 50.4, 593]\n",
      "[10, 100000.0, 0.6, 3, 56.53333333333334, 52.400000000000006, 593]\n"
     ]
    }
   ],
   "source": [
    "print(len(stat))\n",
    "for i in stat:\n",
    "    print(i)\n",
    "    \n",
    "#here stat[i][0]=K\n",
    "#stat[i][1]=c\n",
    "#stat[i][2]=epsilon\n",
    "#stat[i][3]=kernel type , 0-linear, 1-poly ,2-RBF ,3-SIGMOID\n",
    "#stat[i][4]=training accurcy\n",
    "#stat[i][5]=testing accurcy \n",
    "#stat[i][6]=NO OF SUPPORT VECTORS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
